import json
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
from pathlib import Path
import tensorflow as tf
import warnings
warnings.filterwarnings('ignore')

TENSORFLOW_AVAILABLE = True

def load_autokeras_results():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã AutoKeras –∏–∑ —Ñ–∞–π–ª–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
    print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ AutoKeras –∏–∑ –ø–∞–ø–∫–∏ results/autokeras/")
    
    base_path = Path("results/autokeras")
    results = {}
    
    if not base_path.exists():
        print("‚ö† –ü–∞–ø–∫–∞ results/autokeras/ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        print("   –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã Series A")
        return {}
    
    # –°–∫–∞–Ω–∏—Ä—É–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã (bank, housing, churn)
    for dataset_dir in base_path.iterdir():
        if dataset_dir.is_dir():
            dataset_name = dataset_dir.name
            results[dataset_name] = {}
            
            print(f"\n  –î–∞—Ç–∞—Å–µ—Ç: {dataset_name}")
            
            # –°–∫–∞–Ω–∏—Ä—É–µ–º –ø–∞–ø–∫–∏ —Å seeds (seed_42, seed_43, seed_44)
            seed_dirs = list(dataset_dir.glob('seed_*'))
            if not seed_dirs:
                print(f"    ‚ö† –ù–µ—Ç –ø–∞–ø–æ–∫ —Å seeds")
                continue
            
            # –î–ª—è –∫–∞–∂–¥–æ–≥–æ trials –∑–Ω–∞—á–µ–Ω–∏—è (7, 15, 30, 60)
            trial_values = []
            
            for seed_dir in seed_dirs:
                if seed_dir.is_dir():
                    seed = seed_dir.name.replace('seed_', '')
                    
                    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ñ–∞–π–ª—ã results
                    result_files = list(seed_dir.glob('results_*trials.json'))
                    
                    for result_file in result_files:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ trials
                        filename = result_file.stem
                        trials = int(filename.replace('results_', '').replace('trials', ''))
                        
                        if trials not in trial_values:
                            trial_values.append(trials)
                        
                        try:
                            with open(result_file, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                            
                            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                            if trials not in results[dataset_name]:
                                results[dataset_name][trials] = {}
                            
                            results[dataset_name][trials][seed] = data
                            
                        except Exception as e:
                            print(f"    ‚ö† –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {result_file.name}: {e}")
            
            trial_values.sort()
            print(f"    Trials: {trial_values}")
            print(f"    Seeds: {[d.name.replace('seed_', '') for d in seed_dirs]}")
    
    print(f"\n‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(results)} –¥–∞—Ç–∞—Å–µ—Ç–æ–≤")
    return results

def load_neural_results():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä—É—á–Ω—ã—Ö –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –∏–∑ —Ñ–∞–π–ª–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
    print("\nüìä –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä—É—á–Ω—ã—Ö –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –∏–∑ –ø–∞–ø–∫–∏ results/neural/")
    
    base_path = Path("results/neural")
    results = {}
    
    if not base_path.exists():
        print("‚ö† –ü–∞–ø–∫–∞ results/neural/ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        print("   –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã Series B")
        return {}
    
    # –°–∫–∞–Ω–∏—Ä—É–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã
    for dataset_dir in base_path.iterdir():
        if dataset_dir.is_dir():
            dataset_name = dataset_dir.name
            results[dataset_name] = {}
            
            print(f"\n  –î–∞—Ç–∞—Å–µ—Ç: {dataset_name}")
            
            # –ò—â–µ–º —Ñ–∞–π–ª—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä
            arch_files = list(dataset_dir.glob('*_results.json'))
            
            for arch_file in arch_files:
                arch_name = arch_file.stem.replace('_results', '')
                
                try:
                    with open(arch_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    results[dataset_name][arch_name] = data
                    print(f"    ‚úì –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {arch_name}")
                    
                except Exception as e:
                    print(f"    ‚ö† –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {arch_file.name}: {e}")
    
    print(f"\n‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(results)} –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ —Å —Ä—É—á–Ω—ã–º–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º–∏")
    return results

def print_architectures():
    """–í—ã–≤–æ–¥–∏—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –∏–∑ —Ñ–∞–π–ª–æ–≤ .keras"""
    print("\n" + "="*80)
    print("üèóÔ∏è  –ê–†–•–ò–¢–ï–ö–¢–£–†–´ –ù–ï–ô–†–û–°–ï–¢–ï–ô")
    print("="*80)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ TensorFlow
    if not TENSORFLOW_AVAILABLE:
        print("‚ö† TensorFlow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ù–µ –º–æ–≥—É –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏ .keras")
        print("   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ TensorFlow: pip install tensorflow")
        return
    
    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞–∑–≤–∞–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
    dataset_names = {
        'bank': 'Bank Marketing',
        'housing': 'California Housing',
        'churn': 'Telecom Churn'
    }
    
    # 1. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã AutoKeras (—Ç–æ–ª—å–∫–æ seed_42, trials=60)
    print("\n1. –ê–†–•–ò–¢–ï–ö–¢–£–†–´ AUTOKERAS (seed_42, 60 trials):")
    print("-"*60)
    
    ak_base_path = Path("models/autokeras")
    if not ak_base_path.exists():
        print("‚ö† –ü–∞–ø–∫–∞ models/autokeras/ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    else:
        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
        for dataset in ['bank', 'housing', 'churn']:
            model_path = ak_base_path / dataset / 'seed_42' / 'model_60trials.keras'
            
            if model_path.exists():
                try:
                    print(f"\nüìä –î–∞—Ç–∞—Å–µ—Ç: {dataset_names.get(dataset, dataset.upper())}")
                    print(f"üìÅ –ú–æ–¥–µ–ª—å: {model_path}")
                    
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
                    model = tf.keras.models.load_model(model_path)
                    
                    # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
                    print("\n" + "-"*40)
                    print("–°–≤–æ–¥–∫–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:")
                    print("-"*40)
                    
                    # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–ª–æ—è—Ö
                    total_params = 0
                    trainable_params = 0
                    non_trainable_params = 0
                    
                    print(f"{'–°–ª–æ–π':<25} {'–í—ã—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä':<20} {'–ü–∞—Ä–∞–º–µ—Ç—Ä—ã':<10}")
                    print("-"*60)
                    
                    for i, layer in enumerate(model.layers):
                        output_shape = str(layer.output_shape)
                        if len(output_shape) > 30:
                            output_shape = output_shape[:27] + "..."
                        
                        params = layer.count_params()
                        total_params += params
                        
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                        if layer.trainable:
                            trainable_params += params
                        else:
                            non_trainable_params += params
                        
                        print(f"{layer.name:<25} {output_shape:<20} {params:<10,}")
                    
                    print("-"*60)
                    print(f"–í—Å–µ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {total_params:,}")
                    print(f"–û–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {trainable_params:,}")
                    print(f"–ù–µ–æ–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {non_trainable_params:,}")
                    
                    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—Ö–æ–¥–µ –∏ –≤—ã—Ö–æ–¥–µ
                    print(f"\n–í—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä: {model.input_shape}")
                    print(f"–í—ã—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä: {model.output_shape}")
                    
                except Exception as e:
                    print(f"‚ö† –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ {dataset}: {e}")
            else:
                print(f"‚ö† –ú–æ–¥–µ–ª—å –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞ {dataset} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    # 2. –†—É—á–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (architecture1 –∏ architecture2)
    print("\n\n2. –†–£–ß–ù–´–ï –ê–†–•–ò–¢–ï–ö–¢–£–†–´:")
    print("-"*60)
    
    neural_base_path = Path("models/neural")
    if not neural_base_path.exists():
        print("‚ö† –ü–∞–ø–∫–∞ models/neural/ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    else:
        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
        for dataset in ['bank', 'housing', 'churn']:
            dataset_path = neural_base_path / dataset
            
            if dataset_path.exists():
                print(f"\nüìä –î–∞—Ç–∞—Å–µ—Ç: {dataset_names.get(dataset, dataset.upper())}")
                print("="*50)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
                for arch_num in [1, 2]:
                    model_path = dataset_path / f'architecture{arch_num}.keras'
                    
                    if model_path.exists():
                        try:
                            print(f"\nüèóÔ∏è  –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ {arch_num}:")
                            print(f"üìÅ –ú–æ–¥–µ–ª—å: {model_path}")
                            
                            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
                            model = tf.keras.models.load_model(model_path)
                            
                            # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
                            print("\n" + "-"*40)
                            print("–°–≤–æ–¥–∫–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:")
                            print("-"*40)
                            
                            # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–ª–æ—è—Ö
                            total_params = 0
                            trainable_params = 0
                            non_trainable_params = 0
                            
                            print(f"{'–°–ª–æ–π':<25} {'–¢–∏–ø':<20} {'–í—ã—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä':<25} {'–ü–∞—Ä–∞–º–µ—Ç—Ä—ã':<10}")
                            print("-"*80)
                            
                            for i, layer in enumerate(model.layers):
                                layer_type = layer.__class__.__name__
                                output_shape = str(layer.output_shape)
                                if len(output_shape) > 25:
                                    output_shape = output_shape[:22] + "..."
                                
                                params = layer.count_params()
                                total_params += params
                                
                                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                                if layer.trainable:
                                    trainable_params += params
                                else:
                                    non_trainable_params += params
                                
                                print(f"{layer.name:<25} {layer_type:<20} {output_shape:<25} {params:<10,}")
                            
                            print("-"*80)
                            print(f"–í—Å–µ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {total_params:,}")
                            print(f"–û–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {trainable_params:,}")
                            print(f"–ù–µ–æ–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {non_trainable_params:,}")
                            
                            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                            print(f"\n–í—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä: {model.input_shape}")
                            print(f"–í—ã—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä: {model.output_shape}")
                            
                            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è
                            if len(model.layers) > 0:
                                last_layer = model.layers[-1]
                                if hasattr(last_layer, 'activation'):
                                    print(f"–ê–∫—Ç–∏–≤–∞—Ü–∏—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è: {last_layer.activation.__name__}")
                            
                        except Exception as e:
                            print(f"‚ö† –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ architecture{arch_num}: {e}")
                    else:
                        print(f"‚ö† –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ {arch_num} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞ {dataset}")
                
                print()

def get_problem_type(dataset_name, ak_results):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –∑–∞–¥–∞—á–∏ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    for trials_data in ak_results.get(dataset_name, {}).values():
        for seed_data in trials_data.values():
            if 'problem_type' in seed_data:
                return seed_data['problem_type']
    
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ AutoKeras, –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç—è—Ö
    neural_path = Path(f"results/neural/{dataset_name}")
    if neural_path.exists():
        for arch_file in neural_path.glob('*_results.json'):
            try:
                with open(arch_file, 'r') as f:
                    data = json.load(f)
                    if 'problem_type' in data:
                        return data['problem_type']
            except:
                pass
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ –∏–º–µ–Ω–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
    if dataset_name == 'housing':
        return 'regression'
    else:
        return 'classification'

def get_main_metric(data, problem_type):
    """–ü–æ–ª—É—á–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω—É—é –º–µ—Ç—Ä–∏–∫—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏"""
    if 'test_metrics' not in data:
        return 0
    
    test_metrics = data['test_metrics']
    
    if problem_type == 'classification':
        return test_metrics.get('accuracy', 0)
    else:  # regression
        return test_metrics.get('r2_score', 0)

def get_secondary_metric(data, problem_type):
    """–ü–æ–ª—É—á–∞–µ—Ç –≤—Ç–æ—Ä–æ—Å—Ç–µ–ø–µ–Ω–Ω—É—é –º–µ—Ç—Ä–∏–∫—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏"""
    if 'test_metrics' not in data:
        return 0
    
    test_metrics = data['test_metrics']
    
    if problem_type == 'classification':
        return test_metrics.get('f1_score', 0)
    else:  # regression
        return test_metrics.get('rmse', 0)

def plot_autokeras_results(ak_results):
    """–°—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è AutoKeras"""
    if not ak_results:
        print("\n‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö AutoKeras –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
        return
    
    print("\n" + "="*80)
    print("–ì–†–ê–§–ò–ö–ò –î–õ–Ø AUTOKERAS")
    print("="*80)
    
    os.makedirs("results/plots", exist_ok=True)
    
    for dataset_name, trials_data in ak_results.items():
        if not trials_data:
            continue
        
        print(f"\n  üìä –î–∞—Ç–∞—Å–µ—Ç: {dataset_name.upper()}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–¥–∞—á–∏
        problem_type = get_problem_type(dataset_name, ak_results)
        main_metric_name = "R¬≤ Score" if problem_type == 'regression' else "Accuracy"
        secondary_metric_name = "RMSE" if problem_type == 'regression' else "F1 Score"
        
        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        trials_list = sorted(trials_data.keys())
        
        if len(trials_list) < 2:
            print(f"    ‚ö† –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–∞–∑–Ω—ã—Ö trials –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞")
            continue
        
        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ trials –≤—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –ø–æ seeds
        main_metrics = []
        secondary_metrics = []
        times = []
        
        for trials in trials_list:
            seeds_data = trials_data[trials]
            
            if not seeds_data:
                continue
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ seeds
            main_values = []
            secondary_values = []
            time_values = []
            
            for seed_data in seeds_data.values():
                main_values.append(get_main_metric(seed_data, problem_type))
                secondary_values.append(get_secondary_metric(seed_data, problem_type))
                time_values.append(seed_data.get('training_time_seconds', 0))
            
            if main_values:
                main_metrics.append(np.mean(main_values))
                secondary_metrics.append(np.mean(secondary_values))
                times.append(np.mean(time_values))
        
        if not main_metrics:
            print(f"    ‚ö† –ù–µ—Ç –º–µ—Ç—Ä–∏–∫ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞")
            continue
        
        # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        fig.suptitle(f'Dataset: {dataset_name.upper()} - AutoKeras Results', fontsize=14, fontweight='bold')
        
        # –ì—Ä–∞—Ñ–∏–∫ 1: –û—Å–Ω–æ–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞
        ax1.plot(trials_list, main_metrics, 'b-', linewidth=2.5)
        ax1.set_xlabel('Number of Trials', fontsize=11)
        ax1.set_ylabel(main_metric_name, fontsize=11)
        ax1.set_title(f'{main_metric_name} vs Trials', fontsize=12)
        ax1.grid(True, alpha=0.2)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –≥—Ä–∞—Ñ–∏–∫
        for i, (trial, metric) in enumerate(zip(trials_list, main_metrics)):
            label = f'{metric:.3f}'
            ax1.annotate(label, xy=(trial, metric), xytext=(0, 5),
                        textcoords='offset points', ha='center', va='bottom', fontsize=9)
        
        # –ì—Ä–∞—Ñ–∏–∫ 2: –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
        ax2.plot(trials_list, times, 'r-', linewidth=2.5)
        ax2.set_xlabel('Number of Trials', fontsize=11)
        ax2.set_ylabel('Training Time (seconds)', fontsize=11)
        ax2.set_title('Training Time vs Trials', fontsize=12)
        ax2.grid(True, alpha=0.2)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏
        for i, (trial, time_val) in enumerate(zip(trials_list, times)):
            minutes = time_val / 60
            label = f'{minutes:.1f} min'
            ax2.annotate(label, xy=(trial, time_val), xytext=(0, 5),
                        textcoords='offset points', ha='center', va='bottom', fontsize=9)
        
        plt.tight_layout()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫
        plot_filename = f"results/plots/{dataset_name}_autokeras.png"
        plt.savefig(plot_filename, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"    ‚úÖ –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {plot_filename}")
        
        # –í—ã–≤–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print(f"\n    üìã –†–µ–∑—É–ª—å—Ç–∞—Ç—ã AutoKeras –¥–ª—è {dataset_name}:")
        print(f"    {'Trials':<8} {main_metric_name:<15} {secondary_metric_name:<15} {'Time (min)':<12}")
        print(f"    {'-'*55}")
        for trial, main_metric, secondary_metric, time_val in zip(trials_list, main_metrics, secondary_metrics, times):
            print(f"    {trial:<8} {main_metric:<15.4f} {secondary_metric:<15.4f} {time_val/60:<12.1f}")

def plot_comparison_results(ak_results, neural_results):
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç AutoKeras —Å —Ä—É—á–Ω—ã–º–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º–∏"""
    if not ak_results or not neural_results:
        print("\n‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è AutoKeras –∏ —Ä—É—á–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä")
        return
    
    print("\n" + "="*80)
    print("–°–†–ê–í–ù–ï–ù–ò–ï AUTOKERAS –ò –†–£–ß–ù–´–• –ê–†–•–ò–¢–ï–ö–¢–£–†")
    print("="*80)
    
    os.makedirs("results/plots", exist_ok=True)
    
    for dataset_name in ak_results.keys():
        if dataset_name not in neural_results:
            continue
        
        print(f"\n  üìä –î–∞—Ç–∞—Å–µ—Ç: {dataset_name.upper()}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–¥–∞—á–∏
        problem_type = get_problem_type(dataset_name, ak_results)
        main_metric_name = "R¬≤ Score" if problem_type == 'regression' else "Accuracy"
        
        # –î–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        methods = []
        main_metrics = []
        times = []
        
        # AutoKeras (–±–µ—Ä–µ–º trials=60, seed=42)
        if 60 in ak_results[dataset_name] and '42' in ak_results[dataset_name][60]:
            ak_data = ak_results[dataset_name][60]['42']
            methods.append('AutoKeras (60)')
            main_metrics.append(get_main_metric(ak_data, problem_type))
            times.append(ak_data.get('training_time_seconds', 0))
        
        # –†—É—á–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
        for arch_name in ['architecture1', 'architecture2']:
            if arch_name in neural_results[dataset_name]:
                arch_data = neural_results[dataset_name][arch_name]
                methods.append(f'Arch.{arch_name[-1]}')
                main_metrics.append(get_main_metric(arch_data, problem_type))
                times.append(arch_data.get('training_time_seconds', 0))
        
        if len(methods) < 2:
            print(f"    ‚ö† –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
            continue
        
        # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        fig.suptitle(f'Dataset: {dataset_name.upper()} - Comparison', fontsize=14, fontweight='bold')
        
        # –ì—Ä–∞—Ñ–∏–∫ 1: –û—Å–Ω–æ–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞
        colors = ['blue', 'orange', 'green'][:len(methods)]
        bars1 = ax1.bar(methods, main_metrics, color=colors, alpha=0.8)
        ax1.set_ylabel(main_metric_name, fontsize=11)
        ax1.set_title(f'{main_metric_name} Comparison', fontsize=12)
        ax1.grid(True, alpha=0.2, axis='y')
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
        for bar, metric in zip(bars1, main_metrics):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.005,
                    f'{metric:.3f}', ha='center', va='bottom', fontsize=10)
        
        # –ì—Ä–∞—Ñ–∏–∫ 2: –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
        bars2 = ax2.bar(methods, times, color=colors, alpha=0.8)
        ax2.set_ylabel('Time (seconds)', fontsize=11)
        ax2.set_title('Training Time Comparison', fontsize=12)
        ax2.grid(True, alpha=0.2, axis='y')
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏
        for bar, time_val in zip(bars2, times):
            height = bar.get_height()
            minutes = time_val / 60
            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.005,
                    f'{minutes:.1f} min', ha='center', va='bottom', fontsize=10)
        
        plt.tight_layout()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫
        plot_filename = f"results/plots/{dataset_name}_comparison.png"
        plt.savefig(plot_filename, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"    ‚úÖ –ì—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {plot_filename}")
        
        # –í—ã–≤–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—É —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        print(f"\n    üìã –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –¥–ª—è {dataset_name}:")
        print(f"    {'Method':<20} {main_metric_name:<15} {'Time (min)':<12}")
        print(f"    {'-'*50}")
        for method, metric, time_val in zip(methods, main_metrics, times):
            print(f"    {method:<20} {metric:<15.4f} {time_val/60:<12.1f}")

def print_summary_tables(ak_results):
    """–í—ã–≤–æ–¥–∏—Ç —Å–≤–æ–¥–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º AutoKeras —Å —É—á–µ—Ç–æ–º —Ä–∞–∑–Ω—ã—Ö seeds"""
    if not ak_results:
        print("\n‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö AutoKeras –¥–ª—è —Å–≤–æ–¥–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü")
        return
    
    print("\n" + "="*80)
    print("–°–í–û–î–ù–´–ï –¢–ê–ë–õ–ò–¶–´ (–°–†–ï–î–ù–ï–ï ¬± –°–¢–ê–ù–î–ê–†–¢–ù–û–ï –û–¢–ö–õ–û–ù–ï–ù–ò–ï)")
    print("="*80)
    
    for dataset_name, trials_data in ak_results.items():
        if not trials_data:
            continue
        
        print(f"\nüìä –î–∞—Ç–∞—Å–µ—Ç: {dataset_name.upper()}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–¥–∞—á–∏
        problem_type = get_problem_type(dataset_name, ak_results)
        main_metric_name = "R¬≤ Score" if problem_type == 'regression' else "Accuracy"
        secondary_metric_name = "RMSE" if problem_type == 'regression' else "F1 Score"
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ trials
        trials_list = sorted(trials_data.keys())
        
        # –ö—Ä–∞—Ç–∫–∞—è –∏—Ç–æ–≥–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞
        print(f"\n    üìã –ò–¢–û–ì–û–í–ê–Ø –°–í–û–î–ö–ê –î–õ–Ø {dataset_name.upper()}:")
        print(f"    {'Max Trials':<12} {main_metric_name:<15} {secondary_metric_name:<15} {'–í—Ä–µ–º—è (–º–∏–Ω)':<15}")
        print(f"    {'-'*60}")
        
        for trials in trials_list:
            seeds_data = trials_data[trials]
            
            if not seeds_data:
                continue
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
            main_vals = [get_main_metric(d, problem_type) for d in seeds_data.values()]
            secondary_vals = [get_secondary_metric(d, problem_type) for d in seeds_data.values()]
            time_vals = [d.get('training_time_seconds', 0)/60 for d in seeds_data.values()]
            
            if main_vals:
                mean_main = np.mean(main_vals)
                mean_secondary = np.mean(secondary_vals)
                mean_time = np.mean(time_vals)
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤—ã–≤–æ–¥ —Å –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ–º
                if len(main_vals) > 1:
                    std_main = np.std(main_vals)
                    std_secondary = np.std(secondary_vals)
                    std_time = np.std(time_vals)
                    
                    print(f"    {trials:<12} {mean_main:.4f} ¬± {std_main:.4f}  {mean_secondary:.4f} ¬± {std_secondary:.4f}  {mean_time:.1f} ¬± {std_time:.1f}")
                else:
                    print(f"    {trials:<12} {mean_main:.4f}           {mean_secondary:.4f}           {mean_time:.1f}")

def print_neural_summary_tables(neural_results):
    """–í—ã–≤–æ–¥–∏—Ç —Å–≤–æ–¥–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è —Ä—É—á–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä"""
    if not neural_results:
        return
    
    print("\n" + "="*80)
    print("–°–í–û–î–ù–´–ï –¢–ê–ë–õ–ò–¶–´ –î–õ–Ø –†–£–ß–ù–´–• –ê–†–•–ò–¢–ï–ö–¢–£–†")
    print("="*80)
    
    for dataset_name, architectures in neural_results.items():
        if not architectures:
            continue
        
        print(f"\nüìä –î–∞—Ç–∞—Å–µ—Ç: {dataset_name.upper()}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–¥–∞—á–∏
        problem_type = get_problem_type(dataset_name, {})
        main_metric_name = "R¬≤ Score" if problem_type == 'regression' else "Accuracy"
        secondary_metric_name = "RMSE" if problem_type == 'regression' else "F1 Score"
        
        print(f"\n    –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞          {main_metric_name:<15} {secondary_metric_name:<15} {'–í—Ä–µ–º—è (–º–∏–Ω)':<15}")
        print(f"    {'-'*65}")
        
        for arch_name, arch_data in architectures.items():
            main_metric = get_main_metric(arch_data, problem_type)
            secondary_metric = get_secondary_metric(arch_data, problem_type)
            time_min = arch_data.get('training_time_seconds', 0) / 60
            
            print(f"    {arch_name:<20} {main_metric:<15.4f} {secondary_metric:<15.4f} {time_min:<15.1f}")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"""
    print("="*80)
    print("üìä –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–û–í")
    print("="*80)
    print("–ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞–ø—Ä—è–º—É—é –∏–∑ —Ñ–∞–π–ª–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã")
    print("="*80)
    
    # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    os.makedirs("results/plots", exist_ok=True)
    
    # –í—ã–≤–æ–¥–∏–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π
    print_architectures()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\n1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•:")
    print("-"*40)
    
    ak_results = load_autokeras_results()
    neural_results = load_neural_results()
    
    if not ak_results and not neural_results:
        print("\n‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏!")
        print("   –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã:")
        print("   - Series A: python main.py (–≤—ã–±–µ—Ä–∏—Ç–µ 1)")
        print("   - Series B: python main.py (–≤—ã–±–µ—Ä–∏—Ç–µ 2)")
        return
    
    # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã
    print("\n2. –°–í–û–î–ù–´–ï –¢–ê–ë–õ–ò–¶–´:")
    print("-"*40)
    
    if ak_results:
        print_summary_tables(ak_results)
    
    if neural_results:
        print_neural_summary_tables(neural_results)
    
    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫–∏
    print("\n3. –°–û–ó–î–ê–ù–ò–ï –ì–†–ê–§–ò–ö–û–í:")
    print("-"*40)
    
    if ak_results:
        plot_autokeras_results(ak_results)
    
    if ak_results and neural_results:
        plot_comparison_results(ak_results, neural_results)
    
    print("\n" + "="*80)
    print("‚úÖ –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!")
    print("üìÅ –í—Å–µ –≥—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ: results/plots/")
    print("="*80)

if __name__ == "__main__":
    main()